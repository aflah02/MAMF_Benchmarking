{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b02ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f262a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69aeb86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fad92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all files inside base_path change their extension to .txt\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_path, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        filename, ext = os.path.splitext(file)\n",
    "        new_file_path = os.path.join(base_path, f\"{filename}.txt\")\n",
    "        os.rename(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944f1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep files with 3.12, 2.9.0 and json in the name\n",
    "files = [f for f in files if \"3.12\" in f and \"2.9.0\" in f and f.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a78f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split files on _ and sort by the second part (time of format 2026-01-06-08-39-20)\n",
    "files = sorted(files, key=lambda x: x.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9833418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict where key is third part when split on _ and value are all files with that same part\n",
    "\n",
    "hardware_to_file_map = {}\n",
    "\n",
    "for f in files:\n",
    "    hardware = f.split(\"_\")[2]\n",
    "    if hardware not in hardware_to_file_map:\n",
    "        hardware_to_file_map[hardware] = []\n",
    "    hardware_to_file_map[hardware].append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f7d297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mamf_2026-01-06-08-02-30_H100_py3.12_torch2.9.0.txt',\n",
       " 'mamf_2026-01-06-08-10-18_H100_py3.12_torch2.9.0.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardware_to_file_map['H100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8ddf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_parse = []\n",
    "for k, v in hardware_to_file_map.items():\n",
    "    # Take the last file (most recent) for each hardware\n",
    "    files_to_parse.append(v[-1])\n",
    "    if k == 'H100':\n",
    "        files_to_parse.append(v[-2])  # Also take the second last for H100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c83e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mamf_2026-01-06-08-10-18_H100_py3.12_torch2.9.0.txt',\n",
       " 'mamf_2026-01-06-08-02-30_H100_py3.12_torch2.9.0.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c61652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: mamf_2026-01-06-08-10-18_H100_py3.12_torch2.9.0.txt\n",
      "Processing file: mamf_2026-01-06-08-02-30_H100_py3.12_torch2.9.0.txt\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "for file in files_to_parse:\n",
    "    if 'L4' in file:\n",
    "        # Skip files with '200' or 'L4' or '40GB' in the name\n",
    "        continue\n",
    "    print(f'Processing file: {file}')\n",
    "    subprocess.run(\n",
    "        ['python', r'.\\mamf_log_to_duckdb.py', f'outputs/{file}', 'matmul.duckdb'],\n",
    "        check=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'H100-py3.12-torch2.8.0-bf16': [\n",
    "        'UI\\outputs\\mamf_2026-01-17-17-29-24_H100_py3.12_torch2.8.0_base_img-debian-slim_ResumeFrom-17152x12544x10752.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-16-17-21-23_H100_py3.12_torch2.8.0_base_img-debian-slim_ResumeFrom-12032x15360x9728.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-12-18-37-39_H100_py3.12_torch2.8.0_base_img-debian-slim_ResumeFrom-None.txt'\n",
    "    ],\n",
    "    'H100-py3.12-torch2.7.1-bf16': [\n",
    "        'UI\\outputs\\mamf_2026-01-15-07-46-04_H100_py3.12_torch2.7.1_base_img-debian-slim_ResumeFrom-16896x19200x17664.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-14-05-53-45_H100_py3.12_torch2.7.1_base_img-debian-slim_ResumeFrom-12032x1792x16640.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-12-18-39-57_H100_py3.12_torch2.7.1_base_img-debian-slim_ResumeFrom-None.txt'\n",
    "    ],\n",
    "    'H100-py3.12-torch2.9.0-fp8': [\n",
    "        'UI\\outputs\\mamf_2026-01-12-18-31-39_H100_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-None.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-14-05-57-17_H100_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-16128x15616x18688.txt'\n",
    "    ],\n",
    "    'H100-py3.12-torch2.9.0-bf16': [\n",
    "        'UI\\outputs\\mamf_2026-01-12-18-19-16_H100_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-17152x14336x18944.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-07-18-54-14_H100_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-12032x16896x4864.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-06-18-39-23_H100_py3.12_torch2.9.0_base_img-debian-slim.txt'\n",
    "    ],\n",
    "    'H100-py3.12-torch2.9.0-fp8': [\n",
    "        'UI\\outputs\\mamf_2026-01-14-05-57-17_H100_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-16128x15616x18688.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-12-18-31-39_H100_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-None.txt'\n",
    "    ],\n",
    "    'H200-py3.12-torch2.9.0-fp8': [\n",
    "        'UI\\outputs\\mamf_2026-01-12-18-31-25_H200_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-None.txt',\n",
    "        'UI\\outputs\\mamf_2026-01-14-05-55-28_H200_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-16128x10496x7168.txt'\n",
    "    ],\n",
    "    'H200-py3.12-torch2.9.0-bf16': [\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-12-18-27-30_H200_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-12032x7680x17408.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-06-20-19-39_H200_py3.12_torch2.9.0_base_img-debian-slim.json'\n",
    "    ],\n",
    "    'B200-py3.12-torch2.9.0-bf16': [\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-06-20-15-12_B200_py3.12_torch2.9.0_base_img-debian-slim.json',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-12-18-26-13_B200_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-17152x8192x5120.txt'\n",
    "    ],\n",
    "    'B200-py3.12-torch2.9.0-fp8': [\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-12-18-31-23_B200_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-None.txt'\n",
    "    ],\n",
    "    'A100-80GB-py3.12-torch2.9.0-bf16': [\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-02-07-19-06-08_A100-80GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-14336x13312x19456.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-02-05-18-57-13_A100-80GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-12288x13568x1280.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-14-23-15-04_A100-80GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-9728x17152x3584.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-14-05-52-08_A100-80GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-9728x17152x3584.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-12-18-41-36_A100-80GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-6912x9216x17664.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-06-18-39-31_A100-80GB_py3.12_torch2.9.0_base_img-debian-slim.json'\n",
    "    ],\n",
    "    'A100-40GB-py3.12-torch2.9.0-bf16': [\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-02-07-19-05-37_A100-40GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-14592x19200x3328.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-02-05-18-59-15_A100-40GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-12800x5376x15616.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-14-23-29-38_A100-40GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-10240x17152x3072.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-12-18-42-31_A100-40GB_py3.12_torch2.9.0_base_img-debian-slim_ResumeFrom-7168x15360x14592.txt',\n",
    "        'D:\\Windows Folders\\Desktop\\Benchmark Matmul\\UI\\outputs\\mamf_2026-01-06-20-17-56_A100-40GB_py3.12_torch2.9.0_base_img-debian-slim.json'\n",
    "    ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
